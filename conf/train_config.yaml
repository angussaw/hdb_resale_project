files:
  derived_features:
    read_from_source: postgres
    params:
      table_name: "hdb_training_features"
      columns:
        - month
        - year
        - flat_type
        - storey_range
        - floor_area_sqm
        - flat_model
        - lease_age
        - no_of_malls_within_2_km
        - distance_to_nearest_malls
        - no_of_schools_within_2_km
        - distance_to_nearest_schools
        - no_of_parks_within_2_km
        - distance_to_nearest_parks
        - no_of_MRT_stations_within_2_km
        - distance_to_nearest_MRT_stations
        - region
        - resale_price

label_column: resale_price

defaults:
  - override hydra/sweeper: "optuna"
  - override hydra/sweeper/sampler: "tpe"

hydra:
  sweeper:
    sampler:
      seed: 42
    direction: ["minimize"]
    study_name: "random_seed_tuning"
    storage: null
    n_trials: 35
    n_jobs: 1

    params:
      # model_params.randforest.params.n_estimators: range(100,300,5)
      # model_params.randforest.params.max_depth: range(5,20,1)
      # model_params.randforest.params.min_samples_leaf: range(1,10,1)

      # model_params.ebm.params.max_bins: range(150,250,10)
      # model_params.ebm.params.max_interaction_bins: range(5,32,1)
      # model_params.ebm.params.interactions: range(1,10,1)
      # model_params.ebm.params.learning_rate: range(0.001,0.02,0.01)
      # model_params.ebm.params.min_samples_leaf: range(2,10,1)
      # model_params.ebm.params.max_leaves: range(1,5,1)

      # model_params.xgboost.params.max_depth: range(5,15,1)
      # model_params.xgboost.params.n_estimators: range(100,500,10)
      # model_params.xgboost.params.learning_rate: range(0.1,1.0,0.1)

process_train_data:
  ordinal_encoding:
    - storey_range

  train_test_val_split:
    train_size: 0.7
    test_size: 0.2 # Split between test and eval, leave blank to only have train, test
    random_state: 42

model_params:
  chosen_model: "randforest" # randforest, ebm, xgboost

  randforest:
    model_name: "randforest"
    one_hot_encode: True
    scale_data: False
    params:
      random_state: 42
      n_estimators: 205 #Default: 100
      max_depth: 20
      min_samples_leaf: 1 #Default: 1

  ebm:
    model_name: "ebm"
    one_hot_encode: True
    scale_data: False
    params:
      random_state: 42 #Default: 42
      max_bins: 256 #Default: 256
      max_interaction_bins: 32 #Default: 32
      interactions: 10 #Default: 10
      learning_rate: 0.01 #Default: 0.01
      min_samples_leaf: 2 #Default: 2
      max_leaves: 3 #Default: 3
      inner_bags: 0 #Default: 0
      outer_bags: 8 #Default: 8

  xgboost:
    model_name: "xgboost"
    one_hot_encode: True
    scale_data: False
    params:
      max_depth: 8 #Default: 6
      n_estimators: 480 #Default: 100
      learning_rate: 0.1 #Default: 0.3
      random_state: 42

mlflow:
  artifact_name: 'randforest'
  experiment_name: "best models v1"
  description: 'best models'
  model_name: 'best_randforest_v1.joblib'
  tags:
    model-architecture: "randforest"

evaluator:
  rounding_last_n: 5
  feature_importance_top_n: 10
  no_of_cv_folds: # Leave blank to use train-test or train-val-test split
  shap_explainer: True

optimisation_metric: "val_root_mean_squared_error" # metric for optimisation